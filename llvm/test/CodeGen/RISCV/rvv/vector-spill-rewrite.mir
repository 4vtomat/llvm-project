# NOTE: Assertions have been autogenerated by utils/update_mir_test_checks.py
# RUN: llc -mtriple=riscv64 -mattr=+v -O3 -riscv-vsetvli-after-rvv-regalloc -enable-riscv-spill-rewrite -run-pass=riscv-spill-rewrite %s -o - 2>&1 | FileCheck %s

--- |
  target datalayout = "e-m:e-p:64:64-i64:64-i128:128-n64-S128"
  target triple = "riscv64"

  define void @spill_cross_bb_same_lmul(ptr noundef %in, ptr noundef %out) {
    ret void
  }

  define void @spill_cross_bb_different_lmul_1(ptr noundef %in, ptr noundef %out) {
    ret void
  }

  define void @spill_cross_bb_different_lmul_2(ptr noundef %in, ptr noundef %out) {
    ret void
  }
...
---
name:    spill_cross_bb_same_lmul
tracksRegLiveness: true
stack:
  - { id: 0, offset: 0, size: 8, alignment: 8, type: spill-slot, stack-id: scalable-vector }
body: |
  ; CHECK-LABEL: name: spill_cross_bb_same_lmul
  ; CHECK: bb.0:
  ; CHECK-NEXT:   successors: %bb.2(0x50000000), %bb.1(0x30000000)
  ; CHECK-NEXT:   liveins: $x10, $x11, $x12
  ; CHECK-NEXT: {{  $}}
  ; CHECK-NEXT:   [[COPY:%[0-9]+]]:gpr = COPY $x10
  ; CHECK-NEXT:   [[COPY1:%[0-9]+]]:gpr = COPY $x12
  ; CHECK-NEXT:   [[ADDI:%[0-9]+]]:gprnox0 = ADDI $x0, 32
  ; CHECK-NEXT:   [[COPY2:%[0-9]+]]:gpr = COPY $x11
  ; CHECK-NEXT:   %pt:vr = IMPLICIT_DEF
  ; CHECK-NEXT:   renamable $v8 = PseudoVLE32_V_MF2 %pt, [[COPY]], [[ADDI]], 5 /* e32 */, 2 /* tu, ma */ :: (load unknown-size from %ir.in, align 4)
  ; CHECK-NEXT:   BLT $x0, [[COPY1]], %bb.2
  ; CHECK-NEXT:   PseudoBR %bb.1
  ; CHECK-NEXT: {{  $}}
  ; CHECK-NEXT: bb.1:
  ; CHECK-NEXT:   successors: %bb.2(0x80000000)
  ; CHECK-NEXT: {{  $}}
  ; CHECK-NEXT:   renamable $v8 = PseudoVLE32_V_MF2 %pt, [[COPY]], [[ADDI]], 5 /* e32 */, 2 /* tu, ma */ :: (load unknown-size from %ir.in, align 4)
  ; CHECK-NEXT: {{  $}}
  ; CHECK-NEXT: bb.2:
  ; CHECK-NEXT:   liveins: $v8
  ; CHECK-NEXT: {{  $}}
  ; CHECK-NEXT:   PseudoVSE8_V_MF2 renamable $v8, %stack.0, -1, 3 /* e8 */
  ; CHECK-NEXT:   PseudoVSE32_V_MF2 renamable $v8, [[COPY2]], [[ADDI]], 5 /* e32 */ :: (store unknown-size into %ir.out, align 4)
  ; CHECK-NEXT:   renamable $v8 = PseudoVLE8_V_MF2 undef renamable $v8, %stack.0, -1, 3 /* e8 */, 3 /* ta, ma */
  ; CHECK-NEXT:   PseudoRET implicit $v8
  bb.0:
    successors: %bb.2(0x50000000), %bb.1(0x30000000); %bb.2(62.50%), %bb.1(37.50%)
    liveins: $x10, $x11, $x12
    %3:gpr = COPY $x10
    %5:gpr = COPY $x12
    %6:gprnox0 = ADDI $x0, 32
    %7:gpr = COPY $x11
    %pt:vr = IMPLICIT_DEF
    renamable $v8 = PseudoVLE32_V_MF2 %pt, %3:gpr, %6:gprnox0, 5, 2 :: (load unknown-size from %ir.in, align 4)
    BLT $x0, %5:gpr, %bb.2
    PseudoBR %bb.1
  bb.1:
    successors: %bb.2(0x80000000); %bb.2(100.00%)
    renamable $v8 = PseudoVLE32_V_MF2 %pt, %3:gpr, %6:gprnox0, 5, 2 :: (load unknown-size from %ir.in, align 4)
  bb.2:
    liveins: $v8
    VS1R_V renamable $v8, %stack.0 :: (store unknown-size into %stack.0, align 8)
    PseudoVSE32_V_MF2 renamable $v8, %7:gpr, %6:gprnox0, 5 :: (store unknown-size into %ir.out, align 4)
    renamable $v8 = VL1RE8_V %stack.0 :: (load unknown-size from %stack.0, align 8)
    PseudoRET implicit $v8
...
---
name:    spill_cross_bb_different_lmul_1
tracksRegLiveness: true
stack:
  - { id: 0, offset: 0, size: 8, alignment: 8, type: spill-slot, stack-id: scalable-vector }
body: |
  ; CHECK-LABEL: name: spill_cross_bb_different_lmul_1
  ; CHECK: bb.0:
  ; CHECK-NEXT:   successors: %bb.2(0x50000000), %bb.1(0x30000000)
  ; CHECK-NEXT:   liveins: $x10, $x11, $x12
  ; CHECK-NEXT: {{  $}}
  ; CHECK-NEXT:   [[COPY:%[0-9]+]]:gpr = COPY $x10
  ; CHECK-NEXT:   [[COPY1:%[0-9]+]]:gpr = COPY $x12
  ; CHECK-NEXT:   [[ADDI:%[0-9]+]]:gprnox0 = ADDI $x0, 32
  ; CHECK-NEXT:   [[COPY2:%[0-9]+]]:gpr = COPY $x11
  ; CHECK-NEXT:   %pt:vr = IMPLICIT_DEF
  ; CHECK-NEXT:   renamable $v8 = PseudoVLE16_V_MF4 %pt, [[COPY]], [[ADDI]], 4 /* e16 */, 2 /* tu, ma */ :: (load unknown-size from %ir.in, align 4)
  ; CHECK-NEXT:   BLT $x0, [[COPY1]], %bb.2
  ; CHECK-NEXT:   PseudoBR %bb.1
  ; CHECK-NEXT: {{  $}}
  ; CHECK-NEXT: bb.1:
  ; CHECK-NEXT:   successors: %bb.2(0x80000000)
  ; CHECK-NEXT: {{  $}}
  ; CHECK-NEXT:   renamable $v8 = PseudoVLE16_V_MF2 %pt, [[COPY]], [[ADDI]], 4 /* e16 */, 2 /* tu, ma */ :: (load unknown-size from %ir.in, align 4)
  ; CHECK-NEXT: {{  $}}
  ; CHECK-NEXT: bb.2:
  ; CHECK-NEXT:   liveins: $v8
  ; CHECK-NEXT: {{  $}}
  ; CHECK-NEXT:   PseudoVSE8_V_MF2 renamable $v8, %stack.0, -1, 3 /* e8 */
  ; CHECK-NEXT:   PseudoVSE16_V_M1 renamable $v8, [[COPY2]], [[ADDI]], 4 /* e16 */ :: (store unknown-size into %ir.out, align 4)
  ; CHECK-NEXT:   renamable $v8 = PseudoVLE8_V_MF2 undef renamable $v8, %stack.0, -1, 3 /* e8 */, 3 /* ta, ma */
  ; CHECK-NEXT:   PseudoRET implicit $v8
  bb.0:
    successors: %bb.2(0x50000000), %bb.1(0x30000000); %bb.2(62.50%), %bb.1(37.50%)
    liveins: $x10, $x11, $x12
    %3:gpr = COPY $x10
    %5:gpr = COPY $x12
    %6:gprnox0 = ADDI $x0, 32
    %7:gpr = COPY $x11
    %pt:vr = IMPLICIT_DEF
    renamable $v8 = PseudoVLE16_V_MF4 %pt, %3:gpr, %6:gprnox0, 4, 2 :: (load unknown-size from %ir.in, align 4)
    BLT $x0, %5:gpr, %bb.2
    PseudoBR %bb.1
  bb.1:
    successors: %bb.2(0x80000000); %bb.2(100.00%)
    renamable $v8 = PseudoVLE16_V_MF2 %pt, %3:gpr, %6:gprnox0, 4, 2 :: (load unknown-size from %ir.in, align 4)
  bb.2:
    liveins: $v8
    VS1R_V renamable $v8, %stack.0 :: (store unknown-size into %stack.0, align 8)
    PseudoVSE16_V_M1 renamable $v8, %7:gpr, %6:gprnox0, 4 :: (store unknown-size into %ir.out, align 4)
    renamable $v8 = VL1RE8_V %stack.0 :: (load unknown-size from %stack.0, align 8)
    PseudoRET implicit $v8
...
---
name:    spill_cross_bb_different_lmul_2
tracksRegLiveness: true
stack:
  - { id: 0, offset: 0, size: 8, alignment: 8, type: spill-slot, stack-id: scalable-vector }
body: |
  ; CHECK-LABEL: name: spill_cross_bb_different_lmul_2
  ; CHECK: bb.0:
  ; CHECK-NEXT:   successors: %bb.2(0x50000000), %bb.1(0x30000000)
  ; CHECK-NEXT:   liveins: $x10, $x11, $x12
  ; CHECK-NEXT: {{  $}}
  ; CHECK-NEXT:   [[COPY:%[0-9]+]]:gpr = COPY $x10
  ; CHECK-NEXT:   [[COPY1:%[0-9]+]]:gpr = COPY $x12
  ; CHECK-NEXT:   [[ADDI:%[0-9]+]]:gprnox0 = ADDI $x0, 32
  ; CHECK-NEXT:   [[COPY2:%[0-9]+]]:gpr = COPY $x11
  ; CHECK-NEXT:   %pt:vr = IMPLICIT_DEF
  ; CHECK-NEXT:   renamable $v8 = PseudoVLE32_V_M1 %pt, [[COPY]], [[ADDI]], 5 /* e32 */, 2 /* tu, ma */ :: (load unknown-size from %ir.in, align 4)
  ; CHECK-NEXT:   VS1R_V renamable $v8, %stack.0 :: (store unknown-size into %stack.0, align 8)
  ; CHECK-NEXT:   renamable $v8 = VL1RE8_V %stack.0 :: (load unknown-size from %stack.0, align 8)
  ; CHECK-NEXT:   BLT $x0, [[COPY1]], %bb.2
  ; CHECK-NEXT:   PseudoBR %bb.1
  ; CHECK-NEXT: {{  $}}
  ; CHECK-NEXT: bb.1:
  ; CHECK-NEXT:   successors: %bb.2(0x80000000)
  ; CHECK-NEXT: {{  $}}
  ; CHECK-NEXT:   renamable $v8 = PseudoVLE32_V_MF2 %pt, [[COPY]], [[ADDI]], 5 /* e32 */, 2 /* tu, ma */ :: (load unknown-size from %ir.in, align 4)
  ; CHECK-NEXT: {{  $}}
  ; CHECK-NEXT: bb.2:
  ; CHECK-NEXT:   liveins: $v8
  ; CHECK-NEXT: {{  $}}
  ; CHECK-NEXT:   VS1R_V renamable $v8, %stack.0 :: (store unknown-size into %stack.0, align 8)
  ; CHECK-NEXT:   PseudoVSE32_V_MF2 renamable $v8, [[COPY2]], [[ADDI]], 5 /* e32 */ :: (store unknown-size into %ir.out, align 4)
  ; CHECK-NEXT:   renamable $v8 = VL1RE8_V %stack.0 :: (load unknown-size from %stack.0, align 8)
  ; CHECK-NEXT:   PseudoRET implicit $v8
  bb.0:
    successors: %bb.2(0x50000000), %bb.1(0x30000000); %bb.2(62.50%), %bb.1(37.50%)
    liveins: $x10, $x11, $x12
    %3:gpr = COPY $x10
    %5:gpr = COPY $x12
    %6:gprnox0 = ADDI $x0, 32
    %7:gpr = COPY $x11
    %pt:vr = IMPLICIT_DEF
    renamable $v8 = PseudoVLE32_V_M1 %pt, %3:gpr, %6:gprnox0, 5, 2 :: (load unknown-size from %ir.in, align 4)
    VS1R_V renamable $v8, %stack.0 :: (store unknown-size into %stack.0, align 8)
    renamable $v8 = VL1RE8_V %stack.0 :: (load unknown-size from %stack.0, align 8)
    BLT $x0, %5:gpr, %bb.2
    PseudoBR %bb.1
  bb.1:
    successors: %bb.2(0x80000000); %bb.2(100.00%)
    renamable $v8 = PseudoVLE32_V_MF2 %pt, %3:gpr, %6:gprnox0, 5, 2 :: (load unknown-size from %ir.in, align 4)
  bb.2:
    liveins: $v8
    VS1R_V renamable $v8, %stack.0 :: (store unknown-size into %stack.0, align 8)
    PseudoVSE32_V_MF2 renamable $v8, %7:gpr, %6:gprnox0, 5 :: (store unknown-size into %ir.out, align 4)
    renamable $v8 = VL1RE8_V %stack.0 :: (load unknown-size from %stack.0, align 8)
    PseudoRET implicit $v8
...
